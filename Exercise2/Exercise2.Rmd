---
title: "Ex2_Associate_Rule_Learning"
author: "Markus Köfler"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
packages <- c("tidyverse", "dplyr", "janitor", "stargazer", 
              "haven", 'bigutilsr',  'magrittr', "FinAna",
              "lubridate", "png", 'moments', 'sqldf', "arules",
              "arulesViz")

package_installer <- function (list_of_packages){
  for(package in list_of_packages) {
    if(!require(package, character.only = TRUE)) {
      install.packages(package, dependencies = TRUE)
      require(package, character.only = TRUE)
      }
    else {
      next
    }
  }
}

package_installer(packages)
```

The second exercise is about association rule learning. If not stated
otherwise, use "retail2.csv" as data set. As always, you can use your
own code. Otherwise, you can use the R code/functions provided on
Moodle. **Association rule learning** is a popular, unsupervised
learning technique for discovering interesting relations between
variables based on transactions involving them in large databases. As it
is often used for identifying shopping patterns, it is also known as
market basket analysis.

```{r}
# local folder / working directory
# retail <- read.csv("retail2.csv", sep=";")

# GitHub Link
retail <- read.csv(
  "https://raw.githubusercontent.com/MarkusStefan/Data_Analytics/main/Exercise2/retail2.csv?token=GHSAT0AAAAAACBJAQ7CZWQDFSYIQT3UXJVGZBV267Q", 
  sep=';')

retail[1:10 ,]
```

# (2.1)

In this first question you should practice on calculating support:

## (a)

Calculate support for all sets consisting of one item, e.g. bread. Find
two items with the highest/lowest support.

with $frq(A)$ as the number of occurrences from the total number of
transactions $frq(T) = T$:

$$
supp(A) = \frac{frq(A)}{T}
$$ For one single set

```{r}
# nrow counts the number of rows
frqA <- retail %>% subset(Bread==1) %>% nrow()
T. <- nrow(retail)
suppA <- frqA/T.
suppA
retail[, 2 == 1]
```

packing it into a loop to get the highest support value

```{r}
highest_supp <- c(0, "")
T. <- nrow(retail)
for (i in colnames(retail) ) {
  #frqA <- retail %>% subset(i=1) %>% nrow()
  if (i == "id"){
    next
  }
  #frqA <- retail[, i == 1] %>% nrow()
  frqA <- (retail[[i]]==1) %>% sum()
  suppA <- frqA/T.
  cat(suppA*100, "% (", i, ")\n", sep="" )
  if (suppA > highest_supp[1]) {
    highest_supp[1] <- suppA
    highest_supp[2] <- i
  }
  else {
    next
  }
}
cat("\nhighest support:\t", (as.numeric(highest_supp[1])*100), 
    "% (", highest_supp[2],")", sep="")
```

## (b)

Calculate support for all sets consisting of two items, e.g.
(bread,yogurt). Find two item sets with the highest/lowest support.

```{r}
# creating a list of vector-tuples representing all combinations
bi_sets <- list(c("Bread", "Yogurt"), c("Bread", "Egg"), 
                c("Bread", "Dog_Food"), c("Bread", "Flowers"), 
                c("Yogurt", "Egg"), c("Yogurt", "Dog_Food"), 
                c("Yogurt", "Flowers"), c("Egg", "Dog_Food"), 
                c("Egg", "Flowers"), c("Dog_Food", "Flowers"))

T. <- nrow(retail)
for (pair in bi_sets) {
  A <- pair[1]
  B <- pair[2]
  suppAB <- sum(retail[[A]] == 1 & retail[[B]] == 1) / T.
  cat("The support for ", A, " and ", B, " is ", 
      suppAB*100, "%\n", sep="")
}
```

# (2.2)

Calculate the support, the confidence, and the lift for all rules with
yogurt as LHS and one item as RHS.

**Support**: It indicates how frequently an item set appears in the data
set.

```{r}
T. <- nrow(retail)
# -c(1,3) to disregard the index and yogurt columns
for (i in colnames(retail)[-c(1,3)]) {
  suppAB <- sum(retail$Yogurt == 1 & retail[[i]] == 1) / T.
  cat(paste("The support for Yogurt and", i, "is", 
            suppAB*100, "%\n"), sep="")
}
```

**Confidence**: It says how likely item set B is purchased when item set
A is purchased

$$
conf(A \to B) = \frac{supp(A,B)}{supp(A)}
$$

with $supp(A,B) = \frac{frq(A,B)}{frq(T)}$ and
$supp(A) = \frac{frq(A)}{frq(T)}$ it holds that:

$$
conf(A \to B) = \frac{supp(A,B)}{supp(A)} = 
\frac{\frac{frq(A,B)}{frq(T)}}{\frac{frq(A)}{frq(T)}} = 
\frac{frq(A,B)}{frq(A)}
$$

```{r}
# -c(1,3) to disregard the index and yogurt columns
for (i in colnames(retail)[-c(1,3)]) {
  # note that the division by T. of both suppAB and suppB is redundant
  suppAB <- sum(retail$Yogurt == 1 & retail[[i]] == 1) / T.
  suppA <- sum(retail$Yogurt == 1) / T.
  confAB <- suppAB / suppA
  cat(paste("The confidence for Yogurt and", i, "is", 
            round(confAB,4)*100, "%\n"), sep="")
}

```

**Lift**: It says how likely item set B is purchased when item set A is
purchased while controlling for how popular item set B is.

Lift is the ratio of the observed support to that expected if A and B
were independent or equivalently the ratio of the confidence of the rule
to the expected confidence of the RHS item set by independence.

$$
lift(A \to B) = \frac{conf(A,B)}{supp(B)} = \frac{supp(A,B)}{supp(A) \times supp(B)}
$$

*Note:*

$$
lift(A \to B) == lift(B \to A)
$$

```{r}
# -c(1,3) to disregard the index [1] and yogurt [3] columns
for (i in colnames(retail)[-c(1,3)]) {
  
  suppAB <- sum(retail$Yogurt == 1 & retail[[i]] == 1) / T.
  suppA <- sum(retail$Yogurt == 1) / T.
  suppB <- sum(retail[[i]] == 1) / T.
  confAB <- suppAB / suppA
  # first method
  liftAB <- confAB / suppB
  # second method
  liftAB <- suppAB / (suppA * suppB)
  cat(paste("The lift for Yogurt and", i, "is", 
            round(liftAB,4), "\n"), sep="")
}

```

# (2.3)

Calculate the support, the confidence, and the lift for all rules with
one item as LHS and one item as RHS, e.g. bread → yogurt and yogurt →
bread. Identify three interesting rules.

*Note that if:*

-   $lift=1$, the occurrence of A and B are independent of each other

-   $lift <1$, the occurrence of A has a negative effect on the
    occurrence of B, and vice versa

-   $lift > 1$, the two occurrences of A and B depend on each other

```{r}
bi_sets <- list(c("Bread", "Yogurt"), c("Bread", "Egg"), 
                c("Bread", "Dog_Food"), c("Bread", "Flowers"), 
                c("Yogurt", "Egg"), c("Yogurt", "Dog_Food"), 
                c("Yogurt", "Flowers"), c("Egg", "Dog_Food"), 
                c("Egg", "Flowers"), c("Dog_Food", "Flowers"))

T. <- nrow(retail)
for (pair in bi_sets) {
  A <- pair[1]
  B <- pair[2]
  suppAB <- sum(retail[[A]] == 1 & retail[[B]] == 1) / T.
  suppA <- sum(retail[[A]] == 1)/T.; suppB <- sum(retail[[B]] == 1)/T.;
  confAB <- suppAB / suppA; confBA <- suppAB / suppB; 
  liftAB <- confAB / suppB; liftBA <- confBA / suppA;
  liftAB <- suppAB / (suppA*suppB); liftBA <- suppAB / (suppB*suppA)
  
  cat("\nsupp(", A, ",", B, ") \t=\t", suppAB*100, "%\n")
  cat("conf(", A, "->", B,")\t=\t",confAB*100, 
      "%\nconf(", B,"->", A, ")\t=\t", confBA*100,"%\n")
  cat("lift(", A, "->", B,")\t=\t",liftAB, 
      "\nlift(", B,"->", A, ")\t=\t", liftBA,"\n")
}
```

[Interpretation:]{.underline}

-   The most frequently bought bundle is {Bread, yogurt} with 55%,
    followed by {yogurt, Egg} with 22%.

-   Surprisingly, the likelihood of "yogurt" being bought is 40% if
    "Dog_Food" is bought. Attention to the interpretation: If the good
    of the LHS is purchased very frequently, the confidence will most
    likely be very high, despite the weak relationship. Lift is the
    better measure to overcome this issue.

-   Looking at the patterns, we may draw the conclusion that products
    and foods which are regarded as staples of the average households
    consumption are, of course, frequently bought together. This does
    not imply that they are necessarily complements to each other.

-   The results suggest, that only the item set {Bread -\> yogurt} (and
    vice versa yields the same result) are positively correlated, for
    all other item sets, they appear to negatively influence each other
    in terms of being purchased together. Hence, "Bread" and "yogurt"
    seem to complement each other.

# (2.4)

Calculate the support, the confidence, and the lift for all rules with
**(bread, egg)** as LHS and one item as RHS, e.g. (bread, egg) → yogurt.

```{r}
T. <- nrow(retail)
# excluding id, bread and egg columns
for(i in colnames(retail)[-c(1,2,4)]) {
  # support
  # note that it is not necessary to explicitly state the condition for each column
  # if the condition for all columns is the same i.e. == 1
  suppA <- sum(retail[["Bread"]] == 1 & retail[["Egg"]] == 1) / T.
         # sum(retail[["Bread"]] ____ & retail[["Egg"]] == 1) == 1 can be left out at ___
  suppB <- sum(retail[[i]] == 1) / T.
          # sum(retail$Bread == 1 & retail$Egg == 1)
  suppAB <- sum(retail[["Bread"]] == 1  & retail[["Egg"]] == 1 & retail[[i]] == 1) / T.
  
  # confidence
  confAB <- suppAB / suppA
  
  # lift
  liftAB <- confAB / suppB
  
  cat(sprintf("{(%s, %s) -> %s}: support=%.2f, confidence=%.2f, lift=%.2f\n", "Bread", "Egg", 
              i, suppA, confAB, liftAB))
}
```

# (2.5)

**Apriori algorithm**

-   Apriori algorithm is the most popular algorithm used for association
    rule mining. The objective is to find subsets that are common to at
    least a minimum number of the item sets. A frequent item set is an
    item set whose support is greater than or equal to minimum support
    threshold.

-   The Apriori property is a downward closure property, which means
    that all nonempty subsets of a frequent item set must also be
    frequent.

-   Apriori algorithm uses a bottom-up approach; and the size of
    frequent subsets is gradually increased, from one-item subsets to
    two-item subsets, then three-item subsets, and so on. Groups of
    candidates at each level are tested against the data for minimum
    support.

## (a)

Use "Groceries" data set. Calculate all interesting (non-empty) rules
with minimal support = 0.01 and minimal confidence = 0.4. Identify three
rules with the highest support, three rules with the highest confidence
and three rules with the highest lift.

```{r}
library(arules)
library(datasets)

data("Groceries")

Groceries 
```

```{r}
Groceries_rules <- apriori(Groceries, 
                           parameter = list(support = 0.01, 
                                            confidence = 0.4))
```

```{r}
# top 3 ruels with highest support
inspect(sort(Groceries_rules, by = "support", 
             decreasing = TRUE)[1:3])
# top 3 rules with highest confidence
inspect(sort(Groceries_rules, by = "confidence", 
             decreasing = TRUE)[1:3])
# top 3 rules with highest lift
inspect(sort(Groceries_rules, by = "lift", 
             decreasing = TRUE)[1:3])
```

[Interpretation:]{.underline}

This means that 5.6% of all transactions contain both "yogurt" and
"whole milk", and that among those transactions, if "yogurt" is
purchased, the likelihood for "whole milk" to be purchased is 40.2% (so,
of all purchases containing "yogurt", 40.2% of them also contain "whole
milk"). The lift value of 1.57 indicates that the presence of "yogurt"
and "whole milk" in a transaction is 1.57 times more likely than would
be expected if the two items were independent.

[Data Mining:]{.underline}

-   The top 3 bundles with the highest support value, consist of \~more
    healthy food choices, which is nice to see. To be more precise, they
    consist of dairy and vegetable products.

-   support rankings are comprised of sets of 2 items; the confidence
    and lift rankings consist of item sets of 2 items, whereas the LHS
    is a tuple of 2 items

-   the confidence ranking suggests, that if products from one category
    are bought, then there is a slightly higher than 58% chance that
    other items from the same product category are bought. E.g.: 58%
    confidence for other vegetables to be purchased in conjunction to
    citrus fruits and root vegetables (category: fruits & vegetables);
    similarily, we can be confident that 58% of purchases indlucing curd
    and yogurt also include whole milk (category: dairy).

-   The bundles with the highest confidence have (roughly) the highest
    lift values, indicating a (strongly) positive relationship.

-   The highest lift values are comprised of "other vegetables" on the
    RHS.

## (b)

Use "Groceries" data set. Calculate all interesting (non-empty) rules
with minimal support = 0.005 and minimal confidence = 0.3. Identify
three rules with the highest support, three rules with the highest
confidence and three rules with the highest lift.

```{r}
Groceries_rules <- apriori(Groceries, 
                           parameter = list(support = 0.005, 
                                            confidence = 0.3))
# top 3 ruels with highest support
inspect(sort(Groceries_rules, by = "support", 
             decreasing = TRUE)[1:3])
# top 3 rules with highest confidence
inspect(sort(Groceries_rules, by = "confidence", 
             decreasing = TRUE)[1:3])
# top 3 rules with highest lift
inspect(sort(Groceries_rules, by = "lift", 
             decreasing = TRUE)[1:3])
```

[Data Mining:]{.underline}

-   Now, the highest lift values become even larger

-   For the ranking of the top 3 bundles according to lift value, the
    highest ranking one consists of a tuple of 3 items on the LHS.
    Thereby, not all items are of the same product category

## (c)

Use "Adult" data set$^1$ . Calculate all interesting (non-empty) rules
with minimal support = 0.5 and minimal confidence = 0.9. Identify three
rules with the highest support, three rules with the highest confidence
and three rules with the highest lift.

$^1$For more information see:
[Adults]{<http://archive.ics.uci.edu/ml/datasets/Adult>}.

*Note:* Labels have are stated on the website. Data set was originally
intended for classification purposes (prediction whether a person makes
over 50K a year) deploying machine learning algorithms such as
Naive-Bayes, Logistic Regression, K-Means Clustering or Artificial
Neural Networks.

```{r}
url <- "https://raw.githubusercontent.com/MarkusStefan/Data_Analytics/main/Exercise2/adult.data"
adults <- read.table(url, header = FALSE, sep = ",") %>% data.frame()
header <- c("age", "workclass", "fnlwgt", "education", "education-num",
            "merital-status", "occupation", "relationship", "race"
            ,"sex", "capital-gain", "capital-loss","hours-per-week", 
            "native-country", "income")
colnames(adults) <- header
#adults %>% View()
```

```{r}
library(arules)
library(datasets)
data("Adult")
library(arulesViz)
itemFrequencyPlot(Adult, type = "absolute", topN = 20)
```

```{r}
rules <- apriori(Adult, parameter = 
                   list(support = 0.5, confidence = 0.9))

# rules by support
rules_supp <- sort(rules, by = "support", decreasing = TRUE)

# top three rules by support
top_rules_supp <- head(rules_supp, n = 3)

# rules by confidence
rules_conf <- sort(rules, by = "confidence", decreasing = TRUE)

# top three rules by confidence
top_rules_conf <- head(rules_conf, n = 3)

# rules by lift
rules_lift <- sort(rules, by = "lift", decreasing = TRUE)

# Get the top three rules by lift
top_rules_lift <- head(rules_lift, n = 3)
```

## (d)

Use "Adult" data set. Calculate all interesting (non-empty) rules with
minimal support = 0.4 and minimal confidence = 0.8. Identify three rules
with the highest support, three rules with the highest confidence and
three rules with the highest lift.

```{r}
rules <- apriori(Adult, parameter = 
                   list(support = 0.4, confidence = 0.8))

# rules by support
rules_supp <- sort(rules, by = "support", decreasing = TRUE)

# top three rules by support
top_rules_supp <- head(rules_supp, n = 3)

# rules by confidence
rules_conf <- sort(rules, by = "confidence", decreasing = TRUE)

# top three rules by confidence
top_rules_conf <- head(rules_conf, n = 3)

# rules by lift
rules_lift <- sort(rules, by = "lift", decreasing = TRUE)

# top three rules by lift
top_rules_lift <- head(rules_lift, n = 3)
```

```{r}
inspect(top_rules_supp)
#cat("\n")
inspect(top_rules_conf)
#cat("\n")
inspect(top_rules_lift)
```

[Data Mining:]{.underline}

-   not very useful conclusions, as some variables are linked, hence,
    imply each other. E.g.: if relationship = Husband, intuition tells
    us that the sex must be male; or if the merital-status =
    Married-civ-spouse, then we can induce that the subject's
    relationship = Husband
