---
title: "Ex1_Prep&Viz"
author: "Markus KÃ¶fler"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# installing and loading required packages
packages <- c("tidyverse", "dplyr", "janitor", "stargazer", 
              "haven", 'bigutilsr',  'magrittr', "FinAna",
              "lubridate", "png")

package_installer <- function (list_of_packages){
  for(package in list_of_packages) {
    if(!require(package, character.only = TRUE)) {
      install.packages(package, dependencies = TRUE)
      require(package, character.only = TRUE)
      }
    else {
      next
    }
  }
}

package_installer(packages)
```

# 1

## 1.1 Outlier analysis I

Consider the data set USJudgeRatings in R

```{r}
# loading the data set 
data("USJudgeRatings")
# store in a shorter variable name USJR
USJR <-  USJudgeRatings
```

### (a) Check the description of the data.

```{r}
# help command ? to retrieve metadata
?USJudgeRatings
# correlation matrix
pairs(USJR, col=6, pch=8)
```

```{r}
# using the pipe-operator %>% to establish a pipeline of functions
USJR %>% summary()
USJR %>% glimpse()
USJR %>% colnames()
USJR 
```

Wee see that the lawyers' names are used to lable the rows. We can
extract these and use them later for analysis. Will we spot
underperformers?

```{r}
lawyers <- rownames(USJR)
lawyers
```

### (b) For all variables: try different instruments for outlier analysis as discussed in

lecture and identify potential outliers. - Boxplots

```{r}
 # i = 1, 2, 3, ..., number of colums
for (i in 1:length(colnames(USJR))) {
  # index for matrices or data frames-> [rows, cols]
  # title for each boxplot
  boxplot(USJR[, i], main= as.character(colnames(USJR)[i]))
}
```

-   z-score $$
    z = \frac{x - \bar{x}}{\sigma} = \frac{x-\mu}{\sigma}
    $$

```{r}
for (i in 1:ncol(USJR)) {
  if (i==1) {
    x <- USJR[,i]
    x_bar <- mean(x)    # mean(USJR[, i])
    sigma <- sd(x)
    z <- (x-x_bar)/sigma
    # create data frame from zscore obtained
    z_scores <- data.frame(z)
  }
  else {
    x <- USJR[,i]
    x_bar <- mean(x)  
    sigma <- sd(x)
    z <- (x-x_bar)/sigma
    z_scores <- z_scores %>% cbind(z)
  }  
}
# renaming the column names by the corresponding variable
colnames(z_scores) <- colnames(USJR)
# adding back the lawyers' names to label the rows
rownames(z_scores) <- lawyers
#z_scores %>% View()
```

count the number of outlier ratings for each lawyer if $-2.7<z<2.7$

```{r}
outlier_df <- ifelse(abs(z_scores) >= 2.8, 1, 0) %>% as.data.frame()
outlier_df
```

```{r}
#rsums <- outlier_df %>% rowSums() %>% as.vector()
#outlier_df <- outlier_df %>% cbind(rsums, lawyers) %>% as.data.frame()

outlier_df <- outlier_df %>% mutate(outlier_df,
                      rsums = (CONT + INTG + DMNR + DILG + CFMG + DECI + PREP + 
                                 FAMI + ORAL + WRIT +PHYS + RTEN))
outlier_df
```

```{r}
# base R barplot
barplot(rowSums(outlier_df), cex.axis=2, las=2, col=2)
# ggplot
ggplot(data=outlier_df, aes(x=lawyers)) +
  geom_bar(aes(weight=rsums))
```

```{r}
outlier_df %>% summarize(lawyers, rsums) %>% arrange(-rsums) %>% head(10)
```

```{r}
outliers <- boxplot(USJudgeRatings, plot = FALSE)$out

# Print the indices of the outliers
cat("Indices of potential outliers:", which(apply(USJudgeRatings, 2, function(x) x %in% outliers)), "\n")
```

outlier clustering with dbscan

```{r}
library(dbscan)
dist_mtx <- dist(USJR)
# perform DBSCAN clustering
cluster <- dbscan(dist_mtx, eps = 1, minPts = 5)

# print the outlier indices
outlier_indices <- which(cluster$cluster == 0)
print(outlier_indices)
```

# 2

## 1.2 Outlier analysis II

### (a) Choose any company from the Austrian Traded Index (ATX) and download

the stock prices for this company in 2022 (daily basis).

```{r}
RBI <- read_csv("https://raw.githubusercontent.com/MarkusStefan/Data_Analytics/main/RBI.VI.csv")
# creating columns for month and year
RBI <- RBI %>% mutate(month = months(RBI$Date),
                      year = year(RBI$Date))
```

### (b) Based on the data from (a), calculate daily revenues of the stock prices.

```{r}
RBI <- RBI %>% mutate(DailyRev =
  (RBI$`Adj Close` - RBI$Open) * RBI$Volume)

ggplot(data=RBI, aes(x=Date, y=DailyRev)) +
  geom_line(col='dark blue')
```

### (c) Try different instruments for outlier analysis as discussed in lecture and identify

potential outliers. - Standardizing the data (z-scores)

```{r}
RBI <- RBI %>% mutate(DailyRevNorm =
  (DailyRev-mean(DailyRev))/sd(DailyRev))

ggplot(data=RBI, aes(x=Date, y=DailyRevNorm)) +
  geom_line(col='dark blue')
```

removing outliers by z-scores

```{r}
library(lubridate)
outliers_RBI <- RBI[abs(RBI$DailyRevNorm) > 3, ] # RBI %>% filter(DailyRevNorm > 5 | DailyRevNorm < 5) 
m <- months(outliers_RBI$Date)
y <- year(outliers_RBI$Date)
outliers_RBI
```

```{r}
barplot(table(m), las=2, col=3)
barplot(table(y), col="pink")
```

-   Outlier analysis with interquantile range

option to spot outliers with `boxplot()`

```{r}
boxplot(RBI$DailyRev)$out

```

function for computing the values of Q1 and Q3

```{r}
q1q3 <- function(x) {
  sorted <- sort(x, decreasing=F)
  # n observations
  n <- length(sorted)
  
  # index of median
  # ceiling() chooses the upper value if remainder results from floor division
  median_index <- ceiling(n / 2)
  
  # first quartile
  q1_index <- ceiling(median_index / 2)
  q1 <- ifelse(median_index %% 2 == 0, 
               (sorted[q1_index] + sorted[q1_index + 1]) / 2, 
               # else
               sorted[q1_index])
  
  # third quartile
  # -1 such that indices are not skewed
  q3_index <- median_index + q1_index - 1
  q3 <- ifelse(median_index %% 2 == 0, 
               (sorted[q3_index] + sorted[q3_index + 1]) / 2, 
               # else
               sorted[q3_index])
  
 t# return results for q1 & q3
  return(list(q1 = q1, q3 = q3))
}

q1q3(RBI$DailyRev)
```

```{r}
q3 <- quantile(sort(RBI$DailyRev), 0.75)
q1 <- quantile(sort(RBI$DailyRev), 0.25)
q1_q3 <- IQR(sort(RBI$DailyRev))

# reomoving values if they fall out of interquartile range by 1.5 times the interquartile range
# ! negates the logical expression, selecting every row where the condition does NOT apply
no_outliers <- RBI[!RBI$DailyRev < (q1-1.5*q1_q3) | RBI$DailyRev > (q3+1.5*q1_q3), ]
no_outliers

```

```{r}
ggplot(data=no_outliers, aes(x=Date, y=DailyRev, col=factor(year))) +
  geom_line() +
  theme_minimal()
  #scale_color_brewer(palette="Spectral")
ggplot(data=no_outliers, aes(x=Date, y=DailyRevNorm, color=month)) +
  geom_line() +
  facet_wrap(~month) #+ scale_color_brewer(palette="Spectral")

```

outliers per month

```{r}
# binary classification, whether revenue is an outlier or not
RBI <- RBI %>% mutate(outlier=ifelse(abs(DailyRevNorm) > 3, 1, 0))
RBI %>% 
    dplyr::group_by(month) %>% 
    drop_na() %>% 
    summarize(total_outliers = sum(outlier)) %>% 
    arrange(-total_outliers)
```

time, when most outliers occured

```{r}
RBI <- RBI %>% mutate(MY=paste(month, year, sep='/'))
RBI %>% 
    dplyr::group_by(MY) %>% 
    summarize(total_outliers = sum(outlier)) %>% 
    arrange(-total_outliers) %>% 
    head(n=10)
```

# 3

## 1.3 Prepare a brief country profile of your country of origin using the data from The World Factbook of CIA and compare the data of 'your' country with the data for Austria. (If your country of origin is Austria you can take any other country for comparison). The country profile should include:

```{r}
#CIA <- read_csv("export.csv", sep=';')
#CIA
countries <- c("AT", "DE")
pop <- c(9000000, 79000000)
public_debt <- c( 99.91, 63.90)
unrate <- c(6.3, 3.54)
gdp <- c()


comparison <- data.frame(countries, pop, unrate)
comparison

#barplot(data=comparison[, 2])
ggplot(comparison, aes(x = countries, y = pop)) +
  geom_bar(stat = "identity", fill = "blue") +
  labs(x = "Country", y = "Population Size") +
  ggtitle("Population Sizes of Germany and Austria")

```

### (a) Four general statistics (plots): population, GDP, unemployment, public debt.

```{r}
library(reticulate)
use_condaenv('C:/Users/HP/AppData/Local/r-miniconda/envs/r-reticulate/python.exe')
conda_create("r-env", python_version = "3.8")

# Activate the environment
use_condaenv("r-env", required = TRUE)

# Install numpy and pandas using conda
conda_install(c("numpy", "pandas"))
```

### (b) One statistics which you choose on your own.

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import requests
url = "https://www.imf.org/external/datamapper/api/v1/NGDP_RPCH/AUT/DEU?year=2023&yaxis=lin"
response = requests.get(url)
data = response.json()

df = pd.read_json(url)

data
```

```{python}
for i in range(10):
  print(i)
```

### (c) All data should be presented in an appropriate way (as discussed in the lecture) to allow for a comparison of two countries.

# 4

## 1.4 Data preparation and visualization

### (a) Download happiness scores from the World Happiness Report (the Gallup World Poll) from www.ourworldindata.org (happiness-cantril-ladder.csv). The main life evaluation question asked in the poll is: "Please imagine a ladder, with steps numbered from 0 at the bottom to 10 at the top. The top of the ladder represents the best possible life for you and the bottom of the ladder represents the worst possible life for you. On which step of the ladder would you say you personally feel you stand at this time?" (Also known as the "Cantril Ladder".)

```{r}
#happy <- read_csv("https://raw.githubusercontent.com/etadpu/open_source_data/main/happiness-cantril-ladder.csv")
happy <- read_csv("https://raw.githubusercontent.com/MarkusStefan/Data_Analytics/main/happiness-cantril-ladder.csv")
# clean column names 
colnames(happy) <- make_clean_names(colnames(happy))
happy
```

### (b) The imported data should consist of 4 columns. Find and present 5 countries with the highest/lowest happiness in 2010 and in 2020.

```{r}
# extracting relevant years form panel data
# remove columns 2 & 3 s.t. only the country and the happyness score remain
# sorting all columns by happyness score in dscending order (-)
#h2010 <- happy[happy$year == 2010 , ] %>% arrange(-cantril_ladder_score) 
#h2020 <- happy[happy$year == 2020, ] %>% arrange(-cantril_ladder_score) 
h2010 <- happy[happy$year == 2010 , -(2:3)] %>% arrange(-cantril_ladder_score) %>% invisible()
h2020 <- happy[happy$year == 2020, -(2:3)] %>% arrange(-cantril_ladder_score) %>% invisible()
# renaming column name 
colnames(h2010)[2] <- "score2010" 
colnames(h2020)[2] <- "score2020"
# selecting the top & bottom 5 rows
head(h2010, 5); top_n(h2010, -5)
head(h2020, 5); top_n(h2020, -5) 

```

### (c) Find 5 countries with the biggest absolute change (both increase and decrease) of happiness between 2010 and 2020. *Take care of countries where data for 2010 or 2020 is missing!*

```{r}
# merging both dataframes on the country column
h_2010_2020 <- merge(h2010, h2020, by="entity", all.x = TRUE)
h_2010_2020
# other option: joining with SQL statement
# renaming colnames s.t. we remove ambiguity 
# (joinin won't work if columns have the same names)
colnames(h2010) <- c("entity2010", "score2010")
colnames(h2020) <- c("entity2020","score2020")
library(sqldf)
sqldf("
      SELECT *
      FROM h2010 
      LEFT JOIN h2020
      ON entity2010 = entity2020
      ")
```

```{r}
h_2010_2020 <- h_2010_2020 %>% 
  mutate(neg_difference = (score2020-score2010),
         pos_difference = (score2020-score2010))
# negative difference = happyness score decreased from 2010 to 2020
h_2010_2020 %>% select(entity, neg_difference) %>%  arrange(neg_difference);
# positive difference = happyness score increased from 2010 to 2020
h_2010_2020 %>% select(entity, pos_difference) %>%  arrange(-pos_difference)
```

# 5

## 1.5 Visual manipulation

### (a) Construct *three* bad or inappropriate visual representations of the data. Inappropriate in the meaning as discussed in the lecture (insufficient informationon data, poor quality, etc.).

```{r}
ggplot(diamonds, aes(cut, carat), color=factor(price)) +
  geom_point() 
ggplot(diamonds, aes(cut, carat), color=factor(price)) +
  geom_line() +
  facet_wrap(~depth)
```

### (b) You can use any data prepared for this exercise. You can also use a new dataset. In addition, you can download annual data on causes of death in a country of your interest from Eurostat. Information on data: standardized death rate [HLTH CD ASDR], total population regarding sex and age, from 1994 to 2010.

```{r}
death <- read.csv("https://raw.githubusercontent.com/MarkusStefan/Data_Analytics/main/Death_Causes_Eurostat.csv")
```

```{r}
pie(x=death[,1], main="EU27 deaths")
legend("topright", inset = 0.05, title = "Legend", legend = death$TIME, fill=rainbow(factor(death$TIME)))
```

```{r}
for (c in 2:ncol(death)){
  if (c==2){
    pool <- data.frame(death$TIME, death[, c], rep(colnames(death)[c], 10))
  }
  else {
    pool <- pool %>% rbind(data.frame(death$TIME, death[, c], rep(colnames(death)[c], 10)))
  }
}
pool <- pool %>% clean_names()
```

```{r}
ggplot(pool, aes(x=pool$death_time) )+
  geom_point(aes(y=pool$death_c)) +
  facet_wrap(~pool$rep_colnames_death_c_10)
```

```{r}
barplot(height = pool$death_c, width=0.001)
```

```{r}
ggplot(pool, aes(x=pool$death_time, y=pool$death_c)) +
  geom_point(col=2) +
  stat_smooth(method='lm')
```
